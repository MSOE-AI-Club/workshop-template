<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8" />
    <link rel="icon" href="./favicon.ico" />
    <!-- Preload is necessary because we show these images when we disconnect from the server,
    but at that point we cannot load these images from the server -->
    <link rel="preload" href="./assets/gradient-yHQUC_QB.png" as="image" />
    <link rel="preload" href="./assets/noise-60BoTA8O.png" as="image" />
    <!-- Preload the fonts -->
    <link rel="preload" href="./assets/Lora-VariableFont_wght-B2ootaw-.ttf" as="font" crossorigin="anonymous" />
    <link rel="preload" href="./assets/PTSans-Regular-CxL0S8W7.ttf" as="font" crossorigin="anonymous" />
    <link rel="preload" href="./assets/PTSans-Bold-D9fedIX3.ttf" as="font" crossorigin="anonymous" />
    <link rel="preload" href="./assets/FiraMono-Regular-BTCkDNvf.ttf" as="font" crossorigin="anonymous" />
    <link rel="preload" href="./assets/FiraMono-Medium-DU3aDxX5.ttf" as="font" crossorigin="anonymous" />
    <link rel="preload" href="./assets/FiraMono-Bold-CLVRCuM9.ttf" as="font" crossorigin="anonymous" />

    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="theme-color" content="#000000" />
    <meta name="description" content="a marimo app" />
    <link rel="apple-touch-icon" href="./apple-touch-icon.png" />
    <link rel="manifest" href="./manifest.json" />

    <script data-marimo="true">
      function __resizeIframe(obj) {
        var scrollbarHeight = 20; // Max between windows, mac, and linux

        function setHeight() {
          var element = obj.contentWindow.document.documentElement;
          // If there is no vertical scrollbar, we don't need to resize the iframe
          if (element.scrollHeight === element.clientHeight) {
            return;
          }

          // Create a new height that includes the scrollbar height if it's visible
          var hasHorizontalScrollbar = element.scrollWidth > element.clientWidth;
          var newHeight = element.scrollHeight + (hasHorizontalScrollbar ? scrollbarHeight : 0);

          // Only update the height if it's different from the current height
          if (obj.style.height !== `${newHeight}px`) {
            obj.style.height = `${newHeight}px`;
          }
        }

        // Resize the iframe to the height of the content and bottom scrollbar height
        setHeight();

        // Resize the iframe when the content changes
        const resizeObserver = new ResizeObserver((entries) => {
          setHeight();
        });
        resizeObserver.observe(obj.contentWindow.document.body);
      }
    </script>
    <marimo-filename hidden>notebook.py</marimo-filename>
    <marimo-mode data-mode='edit' hidden></marimo-mode>
    <marimo-version data-version='0.13.2' hidden></marimo-version>
    <marimo-user-config data-config='{"completion": {"activate_on_typing": true, "copilot": false}, "display": {"theme": "dark", "code_editor_font_size": 14, "default_table_page_size": 10, "default_width": "medium", "cell_output": "above", "dataframes": "rich"}, "formatting": {"line_length": 79}, "keymap": {"preset": "default", "overrides": {}}, "runtime": {"auto_instantiate": true, "auto_reload": "off", "reactive_tests": true, "on_cell_change": "autorun", "watcher_on_save": "lazy", "output_max_bytes": 8000000, "std_stream_max_bytes": 1000000}, "save": {"autosave": "off", "autosave_delay": 1000, "format_on_save": false}, "package_management": {"manager": "pip"}, "server": {"browser": "default", "follow_symlink": false}, "language_servers": {"pylsp": {"enabled": true, "enable_mypy": true, "enable_ruff": true, "enable_flake8": false, "enable_pydocstyle": false, "enable_pylint": false, "enable_pyflakes": false}}, "snippets": {"custom_paths": [], "include_default_snippets": true}}' data-overrides='{}' hidden></marimo-user-config>
    <marimo-app-config data-config='{"width": "compact", "sql_output": "auto"}' hidden></marimo-app-config>
    <marimo-server-token data-token='123' hidden></marimo-server-token>
    <title>embeddings</title>
    <script type="module" crossorigin src="./assets/index-CBYlZPe-.js"></script>
    <link rel="stylesheet" crossorigin href="./assets/index-DQ-mLFwY.css">
  <marimo-wasm hidden=""></marimo-wasm>
    <script>
        if (window.location.protocol === 'file:') {
            alert('Warning: This file must be served by an HTTP server to function correctly.');
        }
    </script>
    
    <style>
        #save-button {
            display: none !important;
        }
        #filename-input {
            display: none !important;
        }
    </style>
    <marimo-code hidden="" data-show-code="false">import%20marimo%0A%0A__generated_with%20%3D%20%220.13.2%22%0Aapp%20%3D%20marimo.App()%0A%0A%0A%40app.cell%0Adef%20_()%3A%0A%20%20%20%20import%20marimo%20as%20mo%20%23%20Run%20me%20before%20anything%20else!%0A%20%20%20%20return%20(mo%2C)%0A%0A%0A%40app.cell%0Adef%20_(mo)%3A%0A%20%20%20%20mo.md(%0A%20%20%20%20%20%20%20%20r%22%22%22%0A%20%20%20%20%20%20%20%20Embeddings%0A%20%20%20%20%20%20%20%20%3D%3D%3D%0A%20%20%20%20%20%20%20%20MSOE%20AI%20Club%20Workshop%0A%20%20%20%20%20%20%20%20%60%60%60%0A%20%20%20%20%20%20%20%20%20%20_____________%0A%20%20%20%20%20%20%20%20%20%2F0%20%20%20%2F%20%20%20%20%20%5C%20%20%5C%0A%20%20%20%20%20%20%20%20%2F%20%20%5C%20M%20A%20I%20C%2F%20%20%2F%5C%0A%20%20%20%20%20%20%20%20%5C%20%2F%20*%20%20%20%20%20%20%2F%20%20%2F%20%2F%0A%20%20%20%20%20%20%20%20%20%5C___%5C____%2F%20%20%40%20%2F%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%5C_%2F_%2F%0A%20%20%20%20%20%20%20%20%60%60%60%0A%20%20%20%20%20%20%20%20(Rosie%20is%20not%20needed!)%0A%0A%20%20%20%20%20%20%20%20Job%20listing%20dataset%20credit%3A%20https%3A%2F%2Fwww.kaggle.com%2Fdatasets%2Fkshitizregmi%2Fjobs-and-job-description%20(You%20don't%20need%20to%20download%20this%20yourself)%0A%0A%20%20%20%20%20%20%20%20Run%20the%20below%20pip%20installs%20now%20so%20we%20don't%20have%20to%20wait%20for%20them%20later%3A%0A%20%20%20%20%20%20%20%20%22%22%22%0A%20%20%20%20)%0A%20%20%20%20return%0A%0A%0A%40app.cell%0Adef%20_(mo)%3A%0A%20%20%20%20mo.md(%0A%20%20%20%20%20%20%20%20r%22%22%22%0A%20%20%20%20%20%20%20%20%3Cspan%20style%3D%22color%3A%23ff5555%3Bfont-weight%3Abold%3Bfont-size%3A1.5rem%3B%22%3E%0A%20%20%20%20%20%20%20%20%20%20%20%20STOP%0A%20%20%20%20%20%20%20%20%3C%2Fspan%3E%0A%0A%20%20%20%20%20%20%20%20...%20or%20keep%20going%20if%20you%20want%20to%20work%20ahead.%0A%0A%20%20%20%20%20%20%20%20---%0A%0A%20%20%20%20%20%20%20%20Last%20year%2C%20%5Ban%20article%5D(https%3A%2F%2Ffoojay.io%2Ftoday%2Findexing-all-of-wikipedia-on-a-laptop%2F)%20was%20published%20showing%20that%20it's%20possible%20to%20search%20all%20of%20Wikipedia%20using%20only%20the%20compute%20power%20of%20a%20laptop.%20The%20article%20itself%20is%20centered%20around%20the%20use%20of%20some%20Java%20library%2C%20but%20today%20we'll%20be%20looking%20at%20the%20underlying%20theory%20that%20makes%20something%20like%20this%20even%20possible%3A%20embeddings.%0A%0A%20%20%20%20%20%20%20%20Embeddings%20are%20an%20extremely%20useful%20tool%20in%20modern%20machine%20learning%2C%20allowing%20raw%20text%20to%20be%20transformed%20into%20numerical%20representations%20that%20computers%20can%20understand.%0A%20%20%20%20%20%20%20%20They%20are%20also%20a%20popular%20interview%20question%20to%20test%20a%20candidate%E2%80%99s%20understanding%20of%20vector%20spaces%2C%20similarity%20metrics%2C%20and%20real-world%20applications.%0A%20%20%20%20%20%20%20%20Beyond%20that%2C%20embeddings%20are%20incredibly%20common%20in%20ML%2C%20powering%20everything%20from%20search%20engines%20and%20recommendation%20systems%20to%20chatbots%20and%20fraud%20detection.%0A%20%20%20%20%20%20%20%20You'll%20see%20embeddings%20being%20used%20everywhere%20if%20you%20look!%20Here%20are%20just%20some%20models%2C%20projects%2C%20and%20papers%20that%20make%20use%20of%20embeddings%3A%0A%20%20%20%20%20%20%20%20-%20%5BThe%20original%20transformer%20paper%20-%20the%20basis%20of%20modern%20LLMs%5D(https%3A%2F%2Farxiv.org%2Fpdf%2F1706.03762)%0A%20%20%20%20%20%20%20%20-%20%5BRAG%20systems%20-%20often%20used%20to%20give%20LLMs%20comprehensive%20access%20to%20much%20more%20information%20than%20they%20could%20normally%20use%20at%20once%5D(https%3A%2F%2Fen.wikipedia.org%2Fwiki%2FRetrieval-augmented_generation)%0A%20%20%20%20%20%20%20%20-%20%5BImage%20generations%20models%20such%20as%20Stable%20Diffusion%5D(https%3A%2F%2Fen.wikipedia.org%2Fwiki%2FStable_Diffusion)%0A%20%20%20%20%20%20%20%20%20%20-%20Note%3A%20images%20are%20generated%20*in%20embedding%20space*!%0A%20%20%20%20%20%20%20%20-%20%5BAudio-continuation%20models%20such%20as%20RAVE%5D(https%3A%2F%2Fgithub.com%2Facids-ircam%2FRAVE)%0A%20%20%20%20%20%20%20%20-%20Modern%20image%20search%20makes%20extensive%20use%20of%20embeddings%0A%20%20%20%20%20%20%20%20-%20Modern%20recommendation%20algorithms%20also%20use%20embeddings%0A%20%20%20%20%20%20%20%20-%20Even%20some%20papers%20published%20by%20MSOE%20students%20involve%20the%20use%20of%20embeddings!%20Here%20are%20a%20few%3A%0A%20%20%20%20%20%20%20%20%20%20-%20%5BAgent%20simulation%20with%20LLMs%5D(https%3A%2F%2Farxiv.org%2Fpdf%2F2409.13753)%0A%20%20%20%20%20%20%20%20%20%20-%20%5BStrategy%20masking%20-%20a%20technique%20to%20control%20model%20behavior%5D(https%3A%2F%2Farxiv.org%2Fpdf%2F2501.05501)%0A%0A%20%20%20%20%20%20%20%20**What%20*are*%20Embeddings%3F**%0A%0A%20%20%20%20%20%20%20%20At%20the%20lowest%20level%2C%20an%20embedding%20is%20just%20stored%20as%20a%20list%20of%20numbers.%20This%20could%20be%20an%20embedding%3A%20%60%5B0.1%2C%200.2%2C%20-0.3%5D%60.%0A%0A%20%20%20%20%20%20%20%20This%20list%20of%20numbers%20is%20best%20interpreted%20as%20a%20point%20or%20direction%20in%20some%20very%20high-dimensional%20space%20that%20represents%20something.%20In%20the%20case%20of%20text-based%20models%2C%20embeddings%20are%20used%20to%20represent%20words%20and%20sentences.%0A%0A%20%20%20%20%20%20%20%20In%20practice%2C%20embeddings%20range%20from%20tens%20of%20dimensions%20to%20over%201000.%20For%20simplicity%2C%20let's%20only%20conceptualize%20things%20in%20two%20or%20three%20dimensions%20for%20now%20-%20that%20way%20we%20can%20actually%20visualize%20what's%20going%20on.%0A%0A%20%20%20%20%20%20%20%20The%20image%20below%20shows%20how%20embedded%20words%20can%20be%20thought%20of%20as%20directions%20in%20space.%20We're%20specifically%20looking%20at%20words%20in%20the%20phrase%20%60some%20embedded%20text%60.%20Each%20embedding%20point%20describes%20direction%20relative%20to%20the%20point%20(0%2C0).%0A%0A%20%20%20%20%20%20%20%20%3Cimg%20src%3D%22https%3A%2F%2Fraw.githubusercontent.com%2FMSOE-AI-Club%2Fworkshops%2Frefs%2Fheads%2Fmain%2FEmbeddings%2Fimg1.png%22%20width%3D1000px%3E%0A%0A%20%20%20%20%20%20%20%20But%20how%20do%20we%20actually%20interpret%20these%20directions%20in%20space%20as%20being%20words%3F%20The%20answer%20is%20that%20different%20directions%20in%20the%20space%20represent%20different%20aspects%20of%20a%20word%20-%0A%20%20%20%20%20%20%20%20-%20one%20direction%20may%20encode%20%22past%20tense%2C%22%0A%20%20%20%20%20%20%20%20-%20another%20may%20enode%20the%20idea%20of%20%22running%22%20or%20%22to%20run.%22%0A%0A%20%20%20%20%20%20%20%20In%20the%20case%20above%2C%20the%20embedding%20of%20the%20word%20%22ran%22%20may%20point%20in%20the%20average%20of%20the%20directions%20encoding%20%22past%20tense%2C%22%20and%20%22to%20run.%22%0A%0A%20%20%20%20%20%20%20%20%3Cimg%20src%3D%22https%3A%2F%2Fraw.githubusercontent.com%2FMSOE-AI-Club%2Fworkshops%2Frefs%2Fheads%2Fmain%2FEmbeddings%2Fimg2.png%22%20width%3D600px%3E%0A%0A%20%20%20%20%20%20%20%20This%20topic%20naturally%20leads%20into%20another%20important%20point%3A%20embeddings%20*closer*%20in%20embedding%20space%20are%20also%20*closer*%20in%20meaning.%20The%20word%20%22ran%22%20will%20be%20closer%20to%20%22walked%22%20than%20to%20%22stapler.%22%20This%20is%20the%20case%2C%20because%20words%20with%20increasingly%20different%20meanings%20are%2C%20*by%20definition%2C*%20pointing%20in%20increasingly%20different%20directions%20to%20encode%20those%20meanings.%0A%0A%20%20%20%20%20%20%20%20%3Cimg%20src%3D%22https%3A%2F%2Fraw.githubusercontent.com%2FMSOE-AI-Club%2Fworkshops%2Frefs%2Fheads%2Fmain%2FEmbeddings%2Fimg3.png%22%20width%3D600px%3E%0A%0A%20%20%20%20%20%20%20%20NOTE%3A%20we'll%20watch%20this%20during%20the%20workshop%3A%0A%0A%20%20%20%20%20%20%20%20%5BHere%20is%20a%20one-minute%20video%20that%20illustrates%20this%20concept%20using%20real-world%20embeddings.%5D(https%3A%2F%2Fwww.youtube.com%2Fwatch%3Fv%3DFJtFZwbvkI4)%0A%0A%20%20%20%20%20%20%20%20**How%20is%20it%20possible%20for%20there%20to%20be%20directions%20dedicated%20to%20ideas%20as%20specific%20as%20%22Italian-ness%22%20and%20%22WWII%20Axis%20leaders%3F%22**%0A%0A%20%20%20%20%20%20%20%20One%20might%20expect%20that%20the%20directions%20in%20embedding%20space%20would%20represent%20more%20general%20concepts.%0A%0A%20%20%20%20%20%20%20%20If%20directions%20can%20be%20allocated%20to%20specific%20ideas%20like%20%22WWII%20Axis%20leaders%2C%22%20how%20are%20there%20enough%20directions%20left%20to%20represent%20everything%20else%2C%20from%20%2260s%20British%20pop%20bands%22%20to%20%22computer%20keyboard%20layouts%22%3F!%3F!%0A%0A%20%20%20%20%20%20%20%20In%20two%20or%20three%20dimensions%2C%20it's%20*not*%20really%20possible%20to%20have%20directions%20this%20specific.%20But%2C%20remember%20that%20text%20embeddings%20are%20typically%2010s%20to%201000s%20of%20dimensions.%20%20%0A%0A%20%20%20%20%20%20%20%20As%20the%20number%20of%20dimensions%20grows%2C%20the%20number%20of%20possible%20points%20and%20directions%20in%20a%20space%20grows%20MUCH%20more%20quickly.%20More%20directions%20means%20more%20unique%20aspects%20of%20a%20word%20can%20be%20encoded.%0A%0A%20%20%20%20%20%20%20%20Let's%20work%20with%20the%20constraint%20that%20points%20of%20different%20meanings%20must%20be%20one%20unit%20apart.%20This%20is%20somewhat%20arbitrary%2C%20but%20it%20is%20true%20that%20there%20is%20a%20%22minumum%22%20distance%20between%20two%20points%20before%20they%20mean%20the%20same%20thing.%20Let's%20also%20say%20that%20we%20only%20allow%20points%20in%20the%20range%200%20to%201.%20This%20is%20also%20somewhat%20arbitrary%2C%20but%20machine%20learning%20models%20often%20try%20to%20keep%20numbers%20from%20getting%20too%20big%20to%20prevent%20numbers%20from%20going%20to%20infinity.%20With%20these%20constraints%2C%20we%20can%20only%20fit%20two%20points%20in%20one%20dimension%3A%0A%0A%20%20%20%20%20%20%20%20%3Cimg%20src%3D%22https%3A%2F%2Fraw.githubusercontent.com%2FMSOE-AI-Club%2Fworkshops%2Frefs%2Fheads%2Fmain%2FEmbeddings%2Fimg4.png%22%20width%3D600px%3E%0A%0A%20%20%20%20%20%20%20%20These%20two%20points%20(or%20two%20directions%20relative%20to%20a%20centerpoint)%20probably%20can't%20encode%20much%20information.%20Through%20the%20lens%20of%20our%20prior%20examples%2C%20this%20one-dimensional%20space%20could%20only%20encode%20two%20opposite%20meanings%2C%20E.g.%2C%20%22run%22%20and%20%22walk.%22%0A%0A%20%20%20%20%20%20%20%20Now%20what%20if%20we%20extrude%20ourselves%20into%20the%20second%20dimension%20with%20the%20same%20constraints%3F%20%0A%0A%20%20%20%20%20%20%20%20%3Cimg%20src%3D%22https%3A%2F%2Fraw.githubusercontent.com%2FMSOE-AI-Club%2Fworkshops%2Frefs%2Fheads%2Fmain%2FEmbeddings%2Fimg5.png%22%20width%3D600px%3E%0A%0A%20%20%20%20%20%20%20%20We%20now%20have%20*four*%20points%20(or%20four%20directions).%20This%20means%20we%20can%20differentiate%20more%20words.%20For%20instance%2C%20%22run%22%2C%20%22stroll%22%2C%20%22walk%22%2C%20and%20%22jog%22%20could%20have%20unique%20directions.%0A%0A%20%20%20%20%20%20%20%20And%20if%20we%20went%20to%20three%20dimensions%20we'd%20have%20eight%20points%20-%20imagine%20extruding%20the%20four%20points%20of%20this%20square%20into%20a%20cube.%0A%0A%20%20%20%20%20%20%20%20In%20general%2C%20our%20constraints%20will%20allow%20N%20dimensions%20to%20encode%20%242%5EN%24%20unique%20directions.%0A%0A%20%20%20%20%20%20%20%20-%20With%2010%20dimensions%2C%20you%20have%20over%201000%20directions.%0A%20%20%20%20%20%20%20%20-%2020%20dimensions%20gets%20us%20over%201%20million%20directions.%0A%20%20%20%20%20%20%20%20-%20And%20at%201000%20dimensions%2C%20we%20have%20**more%20possible%20unique%20directions%20than%20atoms%20in%20the%20observable%20universe%2C**%20each%20of%20which%20can%20be%20interpolated%20between%20to%20embed%20specific%20words%20or%20sentences!%0A%0A%20%20%20%20%20%20%20%20The%20act%20of%20adding%20just%20*one*%20dimension%20EXPONENTIALLY%20increases%20how%20many%20things%20we%20can%20fit%20in%20the%20space!%20So%20think%20about%20adding%20a%20dimension%20to%20a%203D%20space...%20*1000%20times*.%0A%0A%20%20%20%20%20%20%20%20%3Cimg%20src%3D%22https%3A%2F%2Fwww.i2tutorials.com%2Fwp-content%2Fmedia%2F2019%2F09%2FCurse-of-Dimensionality-i2tutorials.png%22%20width%3D1000px%3E%0A%0A%20%20%20%20%20%20%20%20Although%20we%20can't%20*see*%20the%20directions%20encoding%20things%20like%20%22WWII%20Axis%20leaders%2C%22%20there%20is%20no%20doubt%20that%20these%20directions%20are%20able%20to%20exist.%0A%0A%20%20%20%20%20%20%20%20**Who%20decided%20that%20there%20should%20be%20directions%20for%20these%20particular%20ideas%3F**%0A%0A%20%20%20%20%20%20%20%20These%20directions%20are%20not%20something%20humans%20designed%20directly.%20Instead%2C%20these%20directions%20*emerge*%20from%20the%20process%20of%20training%20the%20model.%0A%0A%20%20%20%20%20%20%20%20The%20model%20learns%20from%20a%20huge%20amount%20of%20text%20and%20starts%20to%20recognize%20patterns%2C%20like%20which%20words%20tend%20to%20appear%20in%20similar%20contexts.%0A%0A%20%20%20%20%20%20%20%20As%20it%20processes%20more%20and%20more%20language%2C%20the%20model%20%22figures%20out%22%20what%20sort%20of%20information%20it%20should%20store%20in%20the%20directions%20of%20an%20embedding%20space%20-%20even%20though%20no%20one%20explicitly%20programmed%20it%20to%20do%20that!%0A%0A%20%20%20%20%20%20%20%20---%0A%0A%20%20%20%20%20%20%20%20%3Cspan%20style%3D%22color%3A%2355ff55%3Bfont-weight%3Abold%3Bfont-size%3A1.5rem%3B%22%3E%0A%20%20%20%20%20%20%20%20%20%20%20%20GO%0A%20%20%20%20%20%20%20%20%3C%2Fspan%3E%0A%0A%20%20%20%20%20%20%20%20**That%20seems%20neat.%20How%20can%20I%20use%20embeddings%3F**%0A%0A%20%20%20%20%20%20%20%20Let's%20set%20things%20up!%0A%0A%20%20%20%20%20%20%20%20It's%20really%20easy%20to%20get%20started%20with%20embeddings.%20You%20can%20even%20run%20small%20embedding%20models%20on%20your%20laptop!%0A%0A%20%20%20%20%20%20%20%20We'll%20be%20using%20%60sentence-transformers%60%20to%20run%20%5Ball-MiniLM-L6-v2%5D(https%3A%2F%2Fhuggingface.co%2Fsentence-transformers%2Fall-MiniLM-L6-v2)%20-%20a%20model%20that%20embeds%20sentences%20into%20384%20dimensions.%0A%20%20%20%20%20%20%20%20%22%22%22%0A%20%20%20%20)%0A%20%20%20%20return%0A%0A%0A%40app.cell%0Adef%20_()%3A%0A%20%20%20%20from%20sentence_transformers%20import%20SentenceTransformer%0A%20%20%20%20import%20numpy%20as%20np%0A%20%20%20%20model%20%3D%20SentenceTransformer(%22all-MiniLM-L6-v2%22)%20%23%20Our%20model%20of%20choice%20is%20supplied%20here.%20You%20can%20find%20many%20more%20on%20huggingface%3A%20https%3A%2F%2Fhuggingface.co%2Fmodels%3Fsort%3Dtrending%26search%3Dembed%0A%20%20%20%20embedding%20%3D%20model.encode(%22This%20is%20an%20embedded%20text%20example.%22)%0A%20%20%20%20return%20embedding%2C%20model%2C%20np%0A%0A%0A%40app.cell%0Adef%20_(mo)%3A%0A%20%20%20%20mo.md(r%22%22%22Our%20embeddings%20are%20just%20lists%20of%20numbers%20stored%20as%20Numpy%20arrays.%20Numpy%20is%20just%20a%20library%20that%20makes%20it%20easier%20to%20manipulate%20arrays.%22%22%22)%0A%20%20%20%20return%0A%0A%0A%40app.cell%0Adef%20_(embedding)%3A%0A%20%20%20%20print(embedding)%0A%20%20%20%20return%0A%0A%0A%40app.cell%0Adef%20_(mo)%3A%0A%20%20%20%20mo.md(%0A%20%20%20%20%20%20%20%20r%22%22%22%0A%20%20%20%20%20%20%20%20%3Cspan%20style%3D%22color%3A%23ff5555%3Bfont-weight%3Abold%3Bfont-size%3A1.5rem%3B%22%3E%0A%20%20%20%20%20%20%20%20%20%20%20%20STOP%0A%20%20%20%20%20%20%20%20%3C%2Fspan%3E%0A%0A%20%20%20%20%20%20%20%20...%20or%20keep%20going%20if%20you%20want%20to%20work%20ahead.%0A%0A%20%20%20%20%20%20%20%20---%0A%0A%20%20%20%20%20%20%20%20Now%20that%20we%20(hopefully)%20have%20a%20working%20embedding%20model%2C%20let's%20put%20it%20to%20use.%0A%0A%20%20%20%20%20%20%20%20But%20before%20that%2C%20we%20need%20to%20understand%20how%20to%20measure%20%22distance%22%20in%20embedding%20space.%0A%0A%20%20%20%20%20%20%20%20**Q%3A%20How%20would%20you%20normally%20measure%20distance%20between%20points%20in%20space%3F**%0A%0A%20%20%20%20%20%20%20%20**A%3A%20I%20would%20use%20the%20%5BPythagorean%20theorem%20to%20find%20the%20Euclidean%20distance%5D(https%3A%2F%2Fen.wikipedia.org%2Fwiki%2FEuclidean_distance).**%0A%0A%20%20%20%20%20%20%20%20That's%20right!%20Except%20we%20don't%20use%20Euclidean%20distance%20for%20embeddings.%0A%0A%20%20%20%20%20%20%20%20Well%2C%20you%20*could*%20use%20Euclidean%20distance%20for%20embeddings%2C%20but%20we%20use%20a%20different%20distance%20metric%20to%20take%20advantage%20of%20the%20fact%20that%20embeddings%20are%20directions.%0A%0A%20%20%20%20%20%20%20%20There%20is%20a%20metric%20you%20can%20compute%20between%20two%20vectors%20(two%20directions)%20called%20the%20%5Bcosine%20similarity%5D(https%3A%2F%2Fen.wikipedia.org%2Fwiki%2FCosine_similarity)%20of%20the%20two%20vectors.%20This%20number%20is%20simply%20the%20cosine%20of%20the%20angle%20between%20the%20vectors.%0A%0A%20%20%20%20%20%20%20%20%3Cimg%20src%3D%22https%3A%2F%2Fraw.githubusercontent.com%2FMSOE-AI-Club%2Fworkshops%2Frefs%2Fheads%2Fmain%2FEmbeddings%2Fimg6.png%22%20width%3D1000px%3E%0A%0A%20%20%20%20%20%20%20%20If%20an%20angle%20%24%5Ctheta%24%20between%20two%20vectors%20is%20small%20and%20close%20to%20zero%2C%20then%20the%20cosine%20of%20that%20value%20will%20be%20close%20to%20%24%5Ccos(0)%20%3D%201%24.%20The%20maximum%20cosine%20similarity%20is%20%241%24.%0A%0A%20%20%20%20%20%20%20%20As%20the%20angle%20increases%2C%20the%20cosine%20similarity%20decreases.%20When%20the%20angle%20passes%20ninety%20degrees%2C%20the%20cosine%20similarity%20goes%20negative.%20Two%20opposite%20vectors%20have%20a%20cosine%20similarity%20of%20%24-1%24.%20**Higher%20cosine%20similarity%20means%20two%20vectors%20are%20more%20similar.**%0A%0A%20%20%20%20%20%20%20%20The%20cosine%20similarity%20is%20so%20useful%20not%20only%20because%20it%20can%20tell%20us%20the%20similarity%20between%20vectors%2C%20but%20*also*%20because%20it's%20really%20easy%20to%20calculate.%20Simply%20multiply%20each%20number%20in%20a%20vector%20with%20each%20number%20in%20the%20same%20position%20in%20another%2C%20and%20then%20take%20the%20sum%3A%0A%20%20%20%20%20%20%20%20%24%24%5Ctext%7BCosineSim%7D(%5B1%2C2%5D%2C%20%5B3%2C4%5D)%20%3D%201%5Ctimes2%5C%20%2B%5C%202%5Ctimes4.%24%24%0A%0A%20%20%20%20%20%20%20%20This%20quantity%20is%20also%20called%20the%20%5Bdot%20product%5D(https%3A%2F%2Fen.wikipedia.org%2Fwiki%2FDot_product)%2C%20and%20we'll%20be%20computing%20it%20via%20%60np.dot%60.%0A%0A%20%20%20%20%20%20%20%20DISCLAIMER%3A%20technically%2C%20the%20dot%20product%20only%20equals%20the%20cosine%20similarity%20when%20the%20vectors%20are%20*normalized*%20(have%20a%20magnitude%20of%201)%2C%20but%20embedding%20vectors%20are%20usually%20normalized.%0A%0A%20%20%20%20%20%20%20%20There%20is%20a%20separate%20metric%20from%20cosine%20similarity%20called%20cosine%20*distance.*%20It%20is%20computed%20via%20%241%20-%20%5Ctext%7BCosineSim%7D%24.%20Unlike%20cosine%20similarity%20which%20tells%20you%20%22how%20similar%22%20two%20vectors%20are%2C%20cosine%20distance%20acts%20more%20like%20Euclidean%20distance%20in%20the%20sense%20that%20higher%20numbers%20mean%20%22more%20different%22%20rather%20than%20%22more%20similar.%22%20The%20cosine%20distance%20ranges%20from%20%240%24%20(for%20two%20equal%20vectors)%20to%20%242%24%20(for%20two%20opposite%20vectors).%0A%0A%20%20%20%20%20%20%20%20If%20you%20*did*%20use%20Euclidean%20distance%20on%20embeddings%2C%20your%20distances%20would%20be%20similar%20to%20those%20from%20using%20cosine%20distance.%20The%20reason%20that%20cosine%20distance%20is%20still%20preferred%20is%20computational%20-%20the%20Euclidean%20distance%20requires%20a%20square%20root%20to%20compute%20while%20cosine%20distance%20doesn't.%0A%0A%20%20%20%20%20%20%20%20---%0A%0A%20%20%20%20%20%20%20%20%3Cspan%20style%3D%22color%3A%2355ff55%3Bfont-weight%3Abold%3Bfont-size%3A1.5rem%3B%22%3E%0A%20%20%20%20%20%20%20%20%20%20%20%20GO%0A%20%20%20%20%20%20%20%20%3C%2Fspan%3E%0A%0A%20%20%20%20%20%20%20%20Let's%20first%20try%20the%20example%20from%20the%20previously%20linked%203Blue1Brown%20video.%0A%0A%20%20%20%20%20%20%20%20Recall%20that%20you%20can%20take%20the%20embedding%20for%20%22Uncle%2C%22%20subtract%20the%20embedding%20for%20%22Man%2C%22%20and%20add%20the%20embedding%20for%20%22Woman.%22%20Doing%20so%20gets%20you%20a%20new%20embedding%20very%20close%20to%20%22aunt.%22%0A%0A%20%20%20%20%20%20%20%20The%20embedding%20of%20%22uncle%22%20is%20already%20close%20to%20%22aunt%22%20because%20they%20share%20meaning%20as%20familial%20roles.%20However%2C%20by%20subtracting%20%22man%22%20and%20adding%20%22woman%2C%22%20we%20are%20shifting%20%22uncle%22%20toward%20its%20female%20counterpart%2C%20%22aunt%2C%22%20in%20the%20embedding%20space.%0A%20%20%20%20%20%20%20%20%22%22%22%0A%20%20%20%20)%0A%20%20%20%20return%0A%0A%0A%40app.cell%0Adef%20_(model%2C%20np)%3A%0A%20%20%20%20emb_uncle%20%3D%20model.encode(%22uncle%22)%0A%20%20%20%20emb_aunt%20%3D%20model.encode(%22aunt%22)%0A%20%20%20%20emb_man%20%3D%20model.encode(%22man%22)%0A%20%20%20%20emb_woman%20%3D%20model.encode(%22woman%22)%0A%0A%20%20%20%20sim1%20%3D%20np.dot(emb_uncle%2C%20emb_aunt)%20%23%20We%20are%20using%20np.dot%20to%20evaluate%20the%20cosine%20similarity%0A%20%20%20%20sim2%20%3D%20np.dot(emb_uncle%20-%20emb_man%20%2B%20emb_woman%2C%20emb_aunt)%0A%0A%20%20%20%20print('CosSim%3A%5Ct%5Ct%5Ct'%2C%20sim1)%0A%20%20%20%20print('CosSim%20after%20transform%3A%5Ct'%2C%20sim2)%20%23%20Higher%20similarity!%20Remember%20that%20a%20larger%20number%20means%20more%20similar.%0A%20%20%20%20return%0A%0A%0A%40app.cell%0Adef%20_(mo)%3A%0A%20%20%20%20mo.md(%0A%20%20%20%20%20%20%20%20r%22%22%22%0A%20%20%20%20%20%20%20%20**If%20you're%20done%20and%20still%20waiting%20for%20the%20workshop%20to%20continue%3A**%0A%0A%20%20%20%20%20%20%20%20Feel%20free%20to%20use%20different%20words%20or%20phrases%20in%20the%20example%20above.%20Does%20the%20%22Hitler%20-%20Germany%20%2B%20Italy%20%3D%20Mussolini%22%20example%20work%3F%20What%20about%20something%20like%20%22Milwaukee%20-%20Wisconsin%20%2B%20Illinois%20%3D%20Chicago%22%3F%0A%0A%20%20%20%20%20%20%20%20%3Cspan%20style%3D%22color%3A%23ff5555%3Bfont-weight%3Abold%3Bfont-size%3A1.5rem%3B%22%3E%0A%20%20%20%20%20%20%20%20%20%20%20%20STOP%0A%20%20%20%20%20%20%20%20%3C%2Fspan%3E%0A%0A%20%20%20%20%20%20%20%20...%20or%20keep%20going%20if%20you%20want%20to%20work%20ahead.%0A%0A%20%20%20%20%20%20%20%20---%0A%0A%20%20%20%20%20%20%20%20**How%20can%20we%20actually%20visualize%20these%20things%20if%20they're%20in%20more%20than%203%20dimensions%3F**%0A%0A%20%20%20%20%20%20%20%20If%20we%20want%20to%20look%20at%20a%20single%20embedding%2C%20there%20are%20a%20few%20approaches%20we%20can%20take%3A%0A%0A%20%20%20%20%20%20%20%20-%20Bar%20graph.%20The%20x%20axis%20represents%20the%20embedding%20dimension%2C%20the%20y%20axis%20represents%20the%20dimension%20value.%0A%20%20%20%20%20%20%20%20%20%20-%20This%20is%20best%20if%20you%20want%20to%20understand%20the%20distribution%20of%20magnitude%20of%20values%20within%20an%20embedding.%0A%20%20%20%20%20%20%20%20-%20Image.%20The%20dimensions%20are%20reshaped%20to%20form%20a%20rectangle%20(in%20our%20case%3A%20384%20-%3E%2016%20by%2024)%2C%20and%20then%20each%20value%20is%20used%20to%20determine%20a%20pixel's%20brightness.%0A%20%20%20%20%20%20%20%20%20%20-%20This%20is%20very%20useful%20if%20you%20want%20to%20see%20a%20%22heatmap%22%20of%20embedding%20space.%20This%20approach%20can%20be%20used%20to%20understand%20which%20dimensions%20are%20%22lighting%20up%22%20under%20certain%20contexts.%20An%20example%20of%20this%20approach%20can%20be%20seen%20in%20%5Bthis%20video%20about%20controlling%20LLM%20behavior%5D(https%3A%2F%2Fwww.youtube.com%2Fwatch%3Fv%3DUGO_Ehywuxc)%20which%20visualizes%20embeddings%20as%20images.%0A%20%20%20%20%20%20%20%20%20%20-%20This%20approach%20can%20also%20be%20useful%20for%20image-embedding%20models.%20With%20image%20embeddings%2C%20certain%20dimensions%20often%20%22light%20up%22%20when%20certain%20visual%20features%20are%20present.%0A%0A%20%20%20%20%20%20%20%20---%0A%0A%20%20%20%20%20%20%20%20%3Cspan%20style%3D%22color%3A%2355ff55%3Bfont-weight%3Abold%3Bfont-size%3A1.5rem%3B%22%3E%0A%20%20%20%20%20%20%20%20%20%20%20%20GO%0A%20%20%20%20%20%20%20%20%3C%2Fspan%3E%0A%0A%20%20%20%20%20%20%20%20Let's%20look%20at%20some%20embeddings!%0A%20%20%20%20%20%20%20%20%22%22%22%0A%20%20%20%20)%0A%20%20%20%20return%0A%0A%0A%40app.cell%0Adef%20_()%3A%0A%20%20%20%20from%20matplotlib%20import%20pyplot%20as%20plt%0A%20%20%20%20return%20(plt%2C)%0A%0A%0A%40app.cell%0Adef%20_(model%2C%20plt)%3A%0A%20%20%20%20NUM_BARS%20%3D%2030%20%23%20set%20to%20some%20big%20number%20(like%201000)%20to%20see%20all%20dimensions%0A%0A%20%20%20%20emb_to_viz%20%3D%20model.encode(%22Milwaukee%22)%0A%0A%20%20%20%20plt.bar(range(emb_to_viz%5B%3ANUM_BARS%5D.size)%2C%20emb_to_viz%5B%3ANUM_BARS%5D)%0A%20%20%20%20plt.show()%0A%0A%20%20%20%20%23%20Two%20embeddings%20in%20one%20plot%0A%0A%20%20%20%20emb_to_viz1%20%3D%20model.encode(%22Milwaukee%22)%0A%20%20%20%20emb_to_viz2%20%3D%20model.encode(%22Chicago%22)%0A%0A%20%20%20%20NUM_BARS%20%3D%2030%0A%20%20%20%20plt.bar(range(emb_to_viz1%5B%3ANUM_BARS%5D.size)%2C%20emb_to_viz1%5B%3ANUM_BARS%5D)%0A%20%20%20%20plt.bar(range(emb_to_viz2%5B%3ANUM_BARS%5D.size)%2C%20emb_to_viz2%5B%3ANUM_BARS%5D)%0A%20%20%20%20plt.show()%0A%20%20%20%20return%0A%0A%0A%40app.cell%0Adef%20_(mo)%3A%0A%20%20%20%20mo.md(r%22%22%22Here%20is%20the%20same%20embedding%20space%20shown%20as%20an%20image.%22%22%22)%0A%20%20%20%20return%0A%0A%0A%40app.cell%0Adef%20_(model%2C%20plt)%3A%0A%20%20%20%20emb_to_viz_1%20%3D%20model.encode('Milwaukee')%0A%20%20%20%20plt.imshow(emb_to_viz_1.reshape(16%2C%2024))%0A%20%20%20%20plt.show()%0A%20%20%20%20return%0A%0A%0A%40app.cell%0Adef%20_(mo)%3A%0A%20%20%20%20mo.md(r%22%22%22Let's%20multiply%20the%20dimensions%20for%20a%20bunch%20of%20cities%20and%20see%20what%20we%20get.%22%22%22)%0A%20%20%20%20return%0A%0A%0A%40app.cell%0Adef%20_(model%2C%20np%2C%20plt)%3A%0A%20%20%20%20city_emb%20%3D%20model.encode('Milwaukee')%0A%20%20%20%20city_emb%20%3D%20city_emb%20*%20model.encode('London')%0A%20%20%20%20city_emb%20%3D%20city_emb%20*%20model.encode('Hong%20Kong')%0A%20%20%20%20city_emb%20%3D%20city_emb%20*%20model.encode('Melbourne')%0A%20%20%20%20city_emb%20%3D%20city_emb%20*%20model.encode('Moscow')%0A%20%20%20%20city_emb%20%3D%20city_emb%20*%20model.encode('Montreal')%0A%20%20%20%20city_emb%20%3D%20city_emb%20*%20model.encode('Cairo')%0A%20%20%20%20city_emb%20%3D%20city_emb%20*%20model.encode('Montevideo')%0A%20%20%20%20city_emb%20%3D%20city_emb%20*%20model.encode('Toronto')%0A%20%20%20%20city_emb%20%3D%20city_emb%20*%20model.encode('Berlin')%0A%20%20%20%20city_emb%20%3D%20np.abs(city_emb)%20**%20(1%20%2F%2010)%0A%20%20%20%20plt.imshow(city_emb.reshape(16%2C%2024))%0A%20%20%20%20return%0A%0A%0A%40app.cell%0Adef%20_(mo)%3A%0A%20%20%20%20mo.md(%0A%20%20%20%20%20%20%20%20r%22%22%22%0A%20%20%20%20%20%20%20%20%3Cspan%20style%3D%22color%3A%23ff5555%3Bfont-weight%3Abold%3Bfont-size%3A1.5rem%3B%22%3E%0A%20%20%20%20%20%20%20%20%20%20%20%20STOP%0A%20%20%20%20%20%20%20%20%3C%2Fspan%3E%0A%0A%20%20%20%20%20%20%20%20...%20or%20keep%20going%20if%20you%20want%20to%20work%20ahead.%0A%0A%20%20%20%20%20%20%20%20---%0A%0A%20%20%20%20%20%20%20%20You'll%20notice%20that%20one%20or%20two%20dimensions%20become%20realy%20prominent%2C%20and%20that%20others%20remain%20fairly%20present.%0A%0A%20%20%20%20%20%20%20%20**Do%20these%20dimensions%20play%20a%20part%20in%20encoding%20information%20about%20geographical%20location%3F**%0A%0A%20%20%20%20%20%20%20%20Kind%20of%2C%20but%20there's%20something%20important%20to%20note%20here.%20Take%20a%20look%20at%20what%20happens%20if%20you%20embed%20the%20word%20%22stapler.%22%20That%20single%20component%20will%20still%20look%20quite%20bright%2C%20but%20%22stapler%22%20isn't%20a%20place.%0A%0A%20%20%20%20%20%20%20%20So%20is%20this%20component%20just%20%22always%20on%22%20for%20any%20input%3F%20Not%20necessarily%2C%20try%20embedding%20%22AI%20Club%22%20and%20you'll%20see%20it%20go%20darker.%20What's%20going%20on%20here%3F%0A%0A%20%20%20%20%20%20%20%20Individual%20dimensions%20are%20very%20difficult%20to%20interpret%2C%20because%20meaning%20comes%20from%20directions%20-%20I.e.%2C%20*combinations*%20of%20dimensions.%20A%20single%20large%20value%20can%20only%20be%20interpreted%20in%20the%20context%20of%20other%20values.%0A%0A%20%20%20%20%20%20%20%20In%20the%20case%20of%20our%20%22city%22%20embedding%2C%20it%20would%20be%20more%20accurate%20to%20say%20that%20the%20most%20prominent%20dimensions%20encode%20geographical%20location%20*in%20the%20context%20of%20other%20dimensions%20being%20their%20values%2C%20even%20if%20those%20values%20are%20smaller.*%0A%0A%20%20%20%20%20%20%20%20We%20will%20soon%20take%20a%20look%20at%20a%20better%20method%20for%20interpreting%20embeddings%3A%20PCA.%20For%20now%2C%20let's%20embed%20some%20real%20data...%0A%0A%20%20%20%20%20%20%20%20---%0A%0A%20%20%20%20%20%20%20%20%3Cspan%20style%3D%22color%3A%2355ff55%3Bfont-weight%3Abold%3Bfont-size%3A1.5rem%3B%22%3E%0A%20%20%20%20%20%20%20%20%20%20%20%20GO%0A%20%20%20%20%20%20%20%20%3C%2Fspan%3E%0A%0A%20%20%20%20%20%20%20%20**Let's%20put%20this%20embedding%20knowledge%20to%20use!**%0A%0A%20%20%20%20%20%20%20%20Since%20embeddings%20are%20a%20popular%20topic%20for%20interview%20questions%2C%20let's%20use%20embeddings%20to%20search%20a%20dataset%20of%20job%20listings.%0A%0A%20%20%20%20%20%20%20%20We%20will%20be%20embedding%20the%20descriptions%20of%20job%20listings.%20Using%20these%20embeddings%2C%20we%20will%20then%20be%20able%20to%20*search*%20all%20of%20the%20job%20listings%20by%20description!%0A%20%20%20%20%20%20%20%20%22%22%22%0A%20%20%20%20)%0A%20%20%20%20return%0A%0A%0A%40app.cell%0Adef%20_()%3A%0A%20%20%20%20import%20pandas%20as%20pd%0A%20%20%20%20return%20(pd%2C)%0A%0A%0A%40app.cell%0Adef%20_(pd)%3A%0A%20%20%20%20%23%20Did%20you%20know%20that%20you%20can%20read%20CSVs%20directly%20from%20a%20URL%3F%0A%20%20%20%20jobs_df%20%3D%20pd.read_csv('https%3A%2F%2Fraw.githubusercontent.com%2FMSOE-AI-Club%2Fworkshops%2Frefs%2Fheads%2Fmain%2FEmbeddings%2Fjob_title_des.csv')%0A%20%20%20%20return%20(jobs_df%2C)%0A%0A%0A%40app.cell%0Adef%20_(jobs_df)%3A%0A%20%20%20%20jobs_df%0A%20%20%20%20return%0A%0A%0A%40app.cell%0Adef%20_(mo)%3A%0A%20%20%20%20mo.md(%0A%20%20%20%20%20%20%20%20r%22%22%22%0A%20%20%20%20%20%20%20%20Here%20is%20our%20dataset%20with%20job%20titles%20and%20job%20descriptions.%0A%0A%20%20%20%20%20%20%20%20Below%20we%20are%20taking%20the%20descriptions%20and%20putting%20them%20all%20through%20our%20embedding%20model.%0A%20%20%20%20%20%20%20%20%22%22%22%0A%20%20%20%20)%0A%20%20%20%20return%0A%0A%0A%40app.cell%0Adef%20_(jobs_df%2C%20model)%3A%0A%20%20%20%20N_JOBS%20%3D%20500%20%23%20Embedding%20ALL%20jobs%20would%20take%20~1%20minute%20on%20a%20CPU%20and%20on%20Rosie%20this%20would%20be%20instant.%20But%20for%20time%2C%20we're%20doing%20500%20jobs.%0A%0A%20%20%20%20%23%20Let's%20also%20save%20the%20job%20titles%20for%20later%0A%20%20%20%20job_titles%20%3D%20jobs_df%5B'Job%20Title'%5D%5B%3AN_JOBS%5D%0A%20%20%20%20job_descs%20%3D%20jobs_df%5B'Job%20Description'%5D%5B%3AN_JOBS%5D%0A%0A%20%20%20%20job_embs%20%3D%20model.encode(job_descs.tolist()%5B%3A500%5D)%0A%20%20%20%20return%20job_descs%2C%20job_embs%2C%20job_titles%0A%0A%0A%40app.cell%0Adef%20_(mo)%3A%0A%20%20%20%20mo.md(%0A%20%20%20%20%20%20%20%20r%22%22%22%0A%20%20%20%20%20%20%20%20We%20are%20using%20a%20trick%20to%20compute%20all%20the%20similarities%20in%20one%20operation%20(rather%20than%20using%20a%20for-loop).%0A%0A%20%20%20%20%20%20%20%20Instead%20of%20iterating%20over%20every%20description%20embedding%2C%20Numpy%20uses%20the%20syntax%20below%20as%20a%20shorthand%20for%20%22evaluate%20the%20dot%20product%20between%20the%20query%20and%20ALL%20descriptions.%22%0A%0A%20%20%20%20%20%20%20%20%60%60%60python%0A%20%20%20%20%20%20%20%20np.dot(query%2C%20job_embs%5B0%5D)%20%23%20Cosine%20similarity%20between%20query%20and%20first%20job.%0A%20%20%20%20%20%20%20%20job_embs%5B0%5D.dot(query)%20%23%20Alternate%20syntax%0A%20%20%20%20%20%20%20%20job_embs.dot(query)%20%23%20Without%20selecting%20a%20specific%20job%20embedding%2C%20we%20broadcast%20our%20singular%20query%20across%20ALL%20jobs%20to%20compute%20ALL%20similarities%20at%20once.%0A%20%20%20%20%20%20%20%20%60%60%60%0A%0A%20%20%20%20%20%20%20%20Remember%20that%20the%20dot%20product%20is%20just%20the%20cosine%20similarity%20in%20our%20case.%20It%20is%20measuring%20how%20similar%20two%20embeddings%20are.%0A%20%20%20%20%20%20%20%20%22%22%22%0A%20%20%20%20)%0A%20%20%20%20return%0A%0A%0A%40app.cell%0Adef%20_(job_embs%2C%20model%2C%20np)%3A%0A%20%20%20%20query%20%3D%20model.encode(%22I%20need%20some%20Python%20for%20AI%22)%20%23%20Search%20for%20jobs%20by%20description%20by%20changing%20this!%0A%20%20%20%20N%20%3D%202%20%23%20get%20the%20Nth%20most%20similar%20job%20in%20addition%20to%20the%20most%20similar%20job%20-%20change%20this%20to%20see%20less%20similar%20results.%0A%0A%20%20%20%20%23%20---%20calculate%20similarities%20---%0A%0A%20%20%20%20similarities%20%3D%20job_embs.dot(query)%20%23%20Cosine%20similarities%20between%20query%20and%20ALL%20jobs.%0A%0A%20%20%20%20%23%20---%20find%20most%20similar%20jobs%20---%0A%0A%20%20%20%20most_similar%20%3D%20np.argmax(similarities)%20%23%20Index%20of%20the%20most%20similar%20job.%0A%20%20%20%20nth_most_similar%20%3D%20np.argsort(similarities)%5B-N%5D%20%23%20Index%20of%20the%20Nth%20most%20similar%20job.%0A%20%20%20%20return%20(most_similar%2C)%0A%0A%0A%40app.cell%0Adef%20_(mo)%3A%0A%20%20%20%20mo.md(r%22%22%22Let's%20take%20a%20look%20at%20our%20results%3A%22%22%22)%0A%20%20%20%20return%0A%0A%0A%40app.cell%0Adef%20_(job_descs%2C%20job_titles%2C%20most_similar)%3A%0A%20%20%20%20print(%0A%20%20%20%20%20%20%20%20f%22Most%20similar%20job%20title%3A%20%7Bjob_titles%5Bmost_similar%5D%7D%22%0A%20%20%20%20%20%20%20%20f%22%5Cn%5CnMost%20similar%20job%20description%3A%5Cn%7Bjob_descs%5Bmost_similar%5D%5B1000%3A%5D%7D%20...%22%0A%20%20%20%20)%0A%20%20%20%20return%0A%0A%0A%40app.cell%0Adef%20_(mo)%3A%0A%20%20%20%20mo.md(%0A%20%20%20%20%20%20%20%20r%22%22%22%0A%20%20%20%20%20%20%20%20%3Cspan%20style%3D%22color%3A%23ff5555%3Bfont-weight%3Abold%3Bfont-size%3A1.5rem%3B%22%3E%0A%20%20%20%20%20%20%20%20%20%20%20%20STOP%0A%20%20%20%20%20%20%20%20%3C%2Fspan%3E%0A%0A%20%20%20%20%20%20%20%20...%20or%20keep%20going%20if%20you%20want%20to%20work%20ahead.%0A%0A%20%20%20%20%20%20%20%20---%0A%0A%20%20%20%20%20%20%20%20You%20now%20have%20the%20knowledge%20to%20perform%20an%20embedding-powered%20search%20across%20any%20textual%20dataset!%0A%0A%20%20%20%20%20%20%20%20**To%20wrap%20things%20up%2C%20let's%20look%20at%20a%20way%20to%20visualize%20ALL%20job%20descriptions'%20embeddings%20at%20once%3A%20dimensionality%20reduction.**%0A%0A%20%20%20%20%20%20%20%20We're%20using%20an%20embedding%20model%20trained%20on%20huge%20amounts%20of%20text%20spanning%20many%20different%20uses%20of%20English.%20However%2C%20our%20current%20task%20only%20spans%20the%20language%20needed%20in%20job%20descriptions.%0A%0A%20%20%20%20%20%20%20%20So%20If%20you%20think%20about%20it%2C%20we%20aren't%20really%20making%20full%20use%20of%20our%20embedding%20space%3B%20there%20is%20some%20redundancy.%20Does%20this%20mean%20there%20could%20there%20be%20a%20way%20to%20do%20the%20same%20thing%20with%20less%20dimensions%3F%20Yes%20it%20does.%0A%0A%20%20%20%20%20%20%20%20In%20general%2C%20if%20your%20task%20doesn't%20span%20the%20entirety%20of%20natural%20language%2C%20you%20can%20perform%20*dimensionality%20reduction*!%20There%20are%20%5Bmany%20ways%20to%20reduce%20the%20number%20of%20dimensions%5D(https%3A%2F%2Fen.wikipedia.org%2Fwiki%2FDimensionality_reduction)%2C%20but%20we'll%20focus%20on%20the%20relatively%20simple%20(yet%20powerful)%20method%20referred%20to%20as%20PCA.%0A%0A%20%20%20%20%20%20%20%20**What's%20a%20PCA%3F**%0A%0A%20%20%20%20%20%20%20%20PCA%20stands%20for%20%22%5Bprinciple%20component%20analysis.%5D(https%3A%2F%2Fen.wikipedia.org%2Fwiki%2FPrincipal_component_analysis)%22%20It's%20a%20technique%20that%20finds%20which%20directions%20in%20a%20high-dimensional%20space%20are%20the%20best%20at%20differentiating%20points%20in%20said%20space.%0A%0A%20%20%20%20%20%20%20%20For%20the%20sake%20of%20example%2C%20let's%20say%20we%20embedded%20our%20job%20descriptions%20into%20two%20dimensions%20and%20they%20looked%20like%20this%3A%0A%0A%20%20%20%20%20%20%20%20%3Cimg%20src%3D%22https%3A%2F%2Fraw.githubusercontent.com%2FMSOE-AI-Club%2Fworkshops%2Frefs%2Fheads%2Fmain%2FEmbeddings%2Fimg7.png%22%20width%3D400px%3E%0A%0A%20%20%20%20%20%20%20%20Looking%20at%20this%2C%20it%20seems%20we%20don't%20really%20*need*%20two%20dimensions%20to%20describe%20all%20of%20our%20jobs.%20We%20can%20just%20use%20a%20single%20number%20to%20say%20how%20far%20they%20are%20along%20a%20line.%20In%20other%20words%3A%20**one%20dimension%20explains%20100%25%20of%20the%20variance%20in%20our%20data.**%0A%0A%20%20%20%20%20%20%20%20More%20realistically%2C%20our%20data%20will%20be%20a%20bit%20more%20noisy%3A%0A%0A%20%20%20%20%20%20%20%20%3Cimg%20src%3D%22https%3A%2F%2Fraw.githubusercontent.com%2FMSOE-AI-Club%2Fworkshops%2Frefs%2Fheads%2Fmain%2FEmbeddings%2Fimg8.png%22%20width%3D400px%3E%0A%0A%20%20%20%20%20%20%20%20But%20it%20could%20still%20be%20the%20case%20that%20the%20majority%20of%20variance%20is%20attributable%20to%20a%20single%20direction.%20In%20this%20case%2C%20we%20may%20perform%20PCA%20and%20find%20that%20one%20dimension%20explains%2090%25%20of%20variance%20while%20the%20other%20explains%2010%25.%0A%0A%20%20%20%20%20%20%20%20In%20general%2C%20PCA%20asks%20%22what%20direction%20most%20strongly%20differentiates%20some%20datapoints%2C%22%20and%20then%20it%20asks%20%22what%20directions%20is%20*second%20best*%20at%20differentiating%20points%22%20and%20so%20on.%0A%0A%20%20%20%20%20%20%20%20This%20process%20repeats%20until%20you%20have%20some%20desired%20number%20of%20reduced%20dimensions.%20We%20will%20be%20using%20PCA%20to%20reduce%20our%20space%20from%20384%20dimensions%20down%20to%202.%0A%0A%20%20%20%20%20%20%20%20---%0A%0A%20%20%20%20%20%20%20%20%3Cspan%20style%3D%22color%3A%2355ff55%3Bfont-weight%3Abold%3Bfont-size%3A1.5rem%3B%22%3E%0A%20%20%20%20%20%20%20%20%20%20%20%20GO%0A%20%20%20%20%20%20%20%20%3C%2Fspan%3E%0A%0A%20%20%20%20%20%20%20%20Let's%20use%20PCA%20on%20our%20job%20listing%20embeddings.%0A%20%20%20%20%20%20%20%20%22%22%22%0A%20%20%20%20)%0A%20%20%20%20return%0A%0A%0A%40app.cell%0Adef%20_()%3A%0A%20%20%20%20from%20sklearn.decomposition%20import%20PCA%20%23%20We%20are%20using%20the%20PCA%20implementation%20from%20scikit-learn%0A%20%20%20%20return%20(PCA%2C)%0A%0A%0A%40app.cell%0Adef%20_(PCA%2C%20job_embs)%3A%0A%20%20%20%20%23%20This%20code%20does%20the%20PCA%20process%20on%20our%20job%20embeddings.%20We%20are%20reducing%20our%20embeddings%20down%20to%20two%20dimensions%0A%20%20%20%20pca%20%3D%20PCA(n_components%3D2)%0A%20%20%20%20job_embs_reduced%20%3D%20pca.fit_transform(job_embs)%0A%20%20%20%20return%20job_embs_reduced%2C%20pca%0A%0A%0A%40app.cell%0Adef%20_(job_embs_reduced)%3A%0A%20%20%20%20job_embs_reduced%5B%3A10%5D%20%23%20the%20first%20ten%20reduced%20embeddings%20-%20they're%20just%20points%20in%202D%20space!%0A%20%20%20%20return%0A%0A%0A%40app.cell%0Adef%20_(job_embs_reduced%2C%20plt)%3A%0A%20%20%20%20plt.scatter(job_embs_reduced%5B%3A%2C0%5D%2C%20job_embs_reduced%5B%3A%2C1%5D)%0A%20%20%20%20plt.axhline(y%3D0.2%2C%20color%3D'red'%2C%20linestyle%3D'-')%0A%20%20%20%20plt.show()%0A%20%20%20%20return%0A%0A%0A%40app.cell%0Adef%20_(mo)%3A%0A%20%20%20%20mo.md(%0A%20%20%20%20%20%20%20%20r%22%22%22%0A%20%20%20%20%20%20%20%20**What%20types%20of%20jobs%20are%20clustering%20over%20y%3D0.2%3F**%0A%0A%20%20%20%20%20%20%20%20It%20looks%20like%20there%20are%20two%20clusters%20of%20points%3A%20one%20larger%20cluster%20below%20%24y%3D0.2%24%20and%20another%20smaller%20one%20above%20%24y%3D0.2%24.%20Let's%20isolate%20points%20in%20these%20clusters%20and%20see%20what%20their%20job%20titles%20are.%0A%20%20%20%20%20%20%20%20%22%22%22%0A%20%20%20%20)%0A%20%20%20%20return%0A%0A%0A%40app.cell%0Adef%20_(job_embs_reduced%2C%20job_titles)%3A%0A%20%20%20%20print('Points%20in%20the%20upper%20cluster%3A')%0A%20%20%20%20print(job_titles%5Bjob_embs_reduced%5B%3A%2C1%5D%3E0.2%5D)%0A%0A%20%20%20%20print('%5CnPoints%20in%20the%20lower%20cluster%3A')%0A%20%20%20%20print(job_titles%5Bjob_embs_reduced%5B%3A%2C1%5D%3C0.2%5D)%0A%20%20%20%20return%0A%0A%0A%40app.cell%0Adef%20_(mo)%3A%0A%20%20%20%20mo.md(%0A%20%20%20%20%20%20%20%20r%22%22%22%0A%20%20%20%20%20%20%20%20%22iOS%22%20and%20%22Flutter%22%20are%20both%20terms%20related%20to%20development%20in%20the%20Apple%20ecosystem.%20It%20seems%20we've%20identified%20a%20cluster%20related%20to%20Apple-related%20job%20positions!%0A%0A%20%20%20%20%20%20%20%20Recall%20that%20we%20can%20determine%20how%20%22good%22%20our%20reduced%20embeddings%20are%20using%20the%20%22explained%20variance%22%20metric.%20Let's%20investigate%20this%20for%20our%20data.%0A%20%20%20%20%20%20%20%20%22%22%22%0A%20%20%20%20)%0A%20%20%20%20return%0A%0A%0A%40app.cell%0Adef%20_(pca)%3A%0A%20%20%20%20print(pca.explained_variance_ratio_)%20%23%20Ratio%20of%20variance%20explained%20per%20dim.%0A%20%20%20%20print(pca.explained_variance_ratio_.sum())%20%23%20Ratio%20of%20varience%20explained%20across%20ALL%202%20dims.%0A%20%20%20%20return%0A%0A%0A%40app.cell%0Adef%20_(mo)%3A%0A%20%20%20%20mo.md(%0A%20%20%20%20%20%20%20%20r%22%22%22%0A%20%20%20%20%20%20%20%20It%20seems%20that%20our%202%20dimensions%20explain%20around%2015%25%20of%20the%20variance%20in%20our%20data.%20This%20means%20we%20aren't%20getting%20the%20full%20picture%20-%2085%25%20of%20the%20data%20remains%20unexplained%20by%20our%202-dimensional%20space.%0A%0A%20%20%20%20%20%20%20%20However%2C%20this%20doesn't%20mean%20our%20results%20aren't%20useful.%20Another%20way%20to%20think%20about%20this%20is%20that%2014%25%20of%20the%20data%20can%20be%20explained%20by%20only%200.5%25%20the%20number%20of%20dimensions.%0A%0A%20%20%20%20%20%20%20%20If%20you%20want%20to%20go%20deeper%2C%20there%20are%20other%20dimenstionality%20reduction%20methods%20to%20try.%20A%20particularly%20interesting%20one%20is%20%5Bumap%5D(https%3A%2F%2Fumap-learn.readthedocs.io%2Fen%2Flatest%2F)%20-%20it's%20like%20PCA%2C%20but%20it%20allows%20for%20non-linear%20transformations.%0A%20%20%20%20%20%20%20%20%22%22%22%0A%20%20%20%20)%0A%20%20%20%20return%0A%0A%0A%40app.cell%0Adef%20_(mo)%3A%0A%20%20%20%20mo.md(%0A%20%20%20%20%20%20%20%20r%22%22%22%0A%20%20%20%20%20%20%20%20%3Cspan%20style%3D%22color%3A%23ff5555%3Bfont-weight%3Abold%3Bfont-size%3A1.5rem%3B%22%3E%0A%20%20%20%20%20%20%20%20%20%20%20%20STOP%0A%20%20%20%20%20%20%20%20%3C%2Fspan%3E%0A%0A%20%20%20%20%20%20%20%20---%0A%0A%20%20%20%20%20%20%20%20Where%20else%20can%20embeddings%20be%20used%3F%0A%0A%20%20%20%20%20%20%20%20-%20Images%20(%5BGoogle%20lens%5D(https%3A%2F%2Fen.wikipedia.org%2Fwiki%2FGoogle_Lens)%2C%20%5BDinoV2%5D(https%3A%2F%2Fdinov2.metademolab.com%2F)%2C%20and%20more)%0A%20%20%20%20%20%20%20%20-%20Audio%20(%5BEncodec%5D(https%3A%2F%2Fgithub.com%2Ffacebookresearch%2Fencodec)%2C%20%5BRAVE%5D(https%3A%2F%2Fgithub.com%2Facids-ircam%2FRAVE%2Ftree%2Fmaster))%0A%20%20%20%20%20%20%20%20-%20%5BAI%20Interpretability%5D(ttps%3A%2F%2Fwww.youtube.com%2Fwatch%3Fv%3DUGO_Ehywuxc)%0A%20%20%20%20%20%20%20%20-%20Classification%20(you%20can%20classify%20%5Btext%5D(https%3A%2F%2Fwww.tensorflow.org%2Ftext%2Ftutorials%2Fclassify_text_with_bert)%20and%20anything%20else%20that%20can%20be%20embedded)%0A%20%20%20%20%20%20%20%20-%20Generative%20AI%20(%5Bstable%20diffusion%20generates%20images%20in%20embedding%20space%20(aka%20%22latent%20space%22)%5D(https%3A%2F%2Fkeras.io%2Fexamples%2Fgenerative%2Frandom_walks_with_stable_diffusion_3%2F))%0A%20%20%20%20%20%20%20%20-%20**Many%2C%20many%2C%20many%20more.**%0A%0A%20%20%20%20%20%20%20%20%23%23%23%20The%20big%20takeaway%3A%0A%0A%20%20%20%20%20%20%20%20Embeddings%20are%20so%20useful%2C%20because%20they%20represent%20abstract%20real-world%20things%20in%20a%20way%20that%20computers%20can%20understand.%0A%0A%20%20%20%20%20%20%20%20If%20a%20problem%20requires%20an%20understanding%20of%20some%20domain%2C%20then%20embeddings%20are%20the%20perfect%20tool.%0A%20%20%20%20%20%20%20%20%22%22%22%0A%20%20%20%20)%0A%20%20%20%20return%0A%0A%0Aif%20__name__%20%3D%3D%20%22__main__%22%3A%0A%20%20%20%20app.run()%0A</marimo-code></head>
  <body>
    <div id="root"></div>
  </body>
</html>
